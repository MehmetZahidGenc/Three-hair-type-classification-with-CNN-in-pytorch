{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n        # print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-02T18:21:09.310023Z","iopub.execute_input":"2022-07-02T18:21:09.310402Z","iopub.status.idle":"2022-07-02T18:21:09.321786Z","shell.execute_reply.started":"2022-07-02T18:21:09.310368Z","shell.execute_reply":"2022-07-02T18:21:09.320675Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom matplotlib import pyplot as plt\nimport cv2\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.359856Z","iopub.execute_input":"2022-07-02T18:21:09.360543Z","iopub.status.idle":"2022-07-02T18:21:09.367487Z","shell.execute_reply.started":"2022-07-02T18:21:09.360505Z","shell.execute_reply":"2022-07-02T18:21:09.366549Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"dataset_path = '../input/the-three-hair-types'","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.389176Z","iopub.execute_input":"2022-07-02T18:21:09.389750Z","iopub.status.idle":"2022-07-02T18:21:09.393547Z","shell.execute_reply.started":"2022-07-02T18:21:09.389695Z","shell.execute_reply":"2022-07-02T18:21:09.392752Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((128, 128)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((128, 128)),\n        transforms.ToTensor()\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.423661Z","iopub.execute_input":"2022-07-02T18:21:09.424240Z","iopub.status.idle":"2022-07-02T18:21:09.430297Z","shell.execute_reply.started":"2022-07-02T18:21:09.424187Z","shell.execute_reply":"2022-07-02T18:21:09.429313Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"full_dataset = ImageFolder(dataset_path, transform=data_transforms['val'])","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.454060Z","iopub.execute_input":"2022-07-02T18:21:09.454462Z","iopub.status.idle":"2022-07-02T18:21:09.467061Z","shell.execute_reply.started":"2022-07-02T18:21:09.454426Z","shell.execute_reply":"2022-07-02T18:21:09.466225Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# %20 of dataset is validation data\ntrain_dataset, val_dataset = random_split(full_dataset, [793, 200])","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.486817Z","iopub.execute_input":"2022-07-02T18:21:09.487189Z","iopub.status.idle":"2022-07-02T18:21:09.492368Z","shell.execute_reply.started":"2022-07-02T18:21:09.487156Z","shell.execute_reply":"2022-07-02T18:21:09.491366Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"batch_size = 90","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.523509Z","iopub.execute_input":"2022-07-02T18:21:09.523862Z","iopub.status.idle":"2022-07-02T18:21:09.527709Z","shell.execute_reply.started":"2022-07-02T18:21:09.523830Z","shell.execute_reply":"2022-07-02T18:21:09.526882Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_dataset, batch_size*2, num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.561603Z","iopub.execute_input":"2022-07-02T18:21:09.562002Z","iopub.status.idle":"2022-07-02T18:21:09.567144Z","shell.execute_reply.started":"2022-07-02T18:21:09.561941Z","shell.execute_reply":"2022-07-02T18:21:09.566150Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"classes = full_dataset.classes\n\nclasses","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.592743Z","iopub.execute_input":"2022-07-02T18:21:09.593127Z","iopub.status.idle":"2022-07-02T18:21:09.598975Z","shell.execute_reply.started":"2022-07-02T18:21:09.593091Z","shell.execute_reply":"2022-07-02T18:21:09.598275Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def display_img(img,label):\n    print(f\"Label : {full_dataset.classes[label]}\")\n    plt.imshow(img.permute(1,2,0))\n\n#display the first image in the dataset\ndisplay_img(*full_dataset[11])","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.624085Z","iopub.execute_input":"2022-07-02T18:21:09.624703Z","iopub.status.idle":"2022-07-02T18:21:09.834852Z","shell.execute_reply.started":"2022-07-02T18:21:09.624663Z","shell.execute_reply":"2022-07-02T18:21:09.833728Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def show_batch(dl):\n    \"\"\"Plot images grid of single batch\"\"\"\n    for images, labels in dl:\n        fig,ax = plt.subplots(figsize = (16,12))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n        break\n        \nshow_batch(train_dl)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:09.836693Z","iopub.execute_input":"2022-07-02T18:21:09.837132Z","iopub.status.idle":"2022-07-02T18:21:13.446283Z","shell.execute_reply.started":"2022-07-02T18:21:09.837082Z","shell.execute_reply":"2022-07-02T18:21:13.444069Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"class ImageClassification(nn.Module):\n\n    def train_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n\n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n\n\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()  # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\n\n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:13.448411Z","iopub.execute_input":"2022-07-02T18:21:13.448745Z","iopub.status.idle":"2022-07-02T18:21:13.458901Z","shell.execute_reply.started":"2022-07-02T18:21:13.448710Z","shell.execute_reply":"2022-07-02T18:21:13.458165Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"class HairModelClassification(ImageClassification):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n        \n            # Layer 1\n            nn.Conv2d(3, 32, kernel_size=3, padding=(2, 2), stride=2),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, padding=(2, 2), stride=2),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            nn.Dropout(0.5),\n            \n            # Layer 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=(2,2), stride=2),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, padding=(2,2), stride=2),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            nn.Dropout(0.5),\n            \n            # layer 3\n            nn.Conv2d(128, 128, kernel_size=3, padding=(2,2), stride=2),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2),\n            nn.Dropout(0.5),\n            \n            # Last layer\n            nn.Flatten(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 3)            \n        )\n\n    def forward(self, xb):\n        return self.network(xb)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:13.460376Z","iopub.execute_input":"2022-07-02T18:21:13.460850Z","iopub.status.idle":"2022-07-02T18:21:13.473908Z","shell.execute_reply.started":"2022-07-02T18:21:13.460815Z","shell.execute_reply":"2022-07-02T18:21:13.472934Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"model = HairModelClassification()","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:13.475373Z","iopub.execute_input":"2022-07-02T18:21:13.476005Z","iopub.status.idle":"2022-07-02T18:21:13.492731Z","shell.execute_reply.started":"2022-07-02T18:21:13.475937Z","shell.execute_reply":"2022-07-02T18:21:13.491716Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\n\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n\n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.train_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:13.494163Z","iopub.execute_input":"2022-07-02T18:21:13.494805Z","iopub.status.idle":"2022-07-02T18:21:13.505264Z","shell.execute_reply.started":"2022-07-02T18:21:13.494756Z","shell.execute_reply":"2022-07-02T18:21:13.504327Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\nopt_func = torch.optim.Adam\nlr = 0.001","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:13.506527Z","iopub.execute_input":"2022-07-02T18:21:13.507014Z","iopub.status.idle":"2022-07-02T18:21:13.521198Z","shell.execute_reply.started":"2022-07-02T18:21:13.506966Z","shell.execute_reply":"2022-07-02T18:21:13.520321Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:21:13.523148Z","iopub.execute_input":"2022-07-02T18:21:13.523622Z","iopub.status.idle":"2022-07-02T18:22:14.862453Z","shell.execute_reply.started":"2022-07-02T18:21:13.523587Z","shell.execute_reply":"2022-07-02T18:22:14.861174Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    \"\"\" Plot the history of accuracies\"\"\"\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n    \n\nplot_accuracies(history)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:22:14.864877Z","iopub.execute_input":"2022-07-02T18:22:14.865237Z","iopub.status.idle":"2022-07-02T18:22:15.083284Z","shell.execute_reply.started":"2022-07-02T18:22:14.865200Z","shell.execute_reply":"2022-07-02T18:22:15.082060Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    \"\"\" Plot the losses in each epoch\"\"\"\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T18:22:15.084731Z","iopub.execute_input":"2022-07-02T18:22:15.085052Z","iopub.status.idle":"2022-07-02T18:22:15.312257Z","shell.execute_reply.started":"2022-07-02T18:22:15.085019Z","shell.execute_reply":"2022-07-02T18:22:15.311091Z"},"trusted":true},"execution_count":70,"outputs":[]}]}